{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "from typing import Union, Tuple, List\n",
    "from transformers import BertConfig, BertForPreTraining, BertTokenizerFast\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from typing import Union, Tuple, List\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "# from IPython.display import Image\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import normal_\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import re\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "import os\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer\n",
    "from transformers.utils import logging\n",
    "from transformers import BertConfig, BertForPreTraining, BertTokenizerFast\n",
    "from filelock import FileLock\n",
    "import time\n",
    "import pickle\n",
    "from transformers import BertConfig, BertForPreTraining\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "import argparse\n",
    "\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer\n",
    "from datetime import datetime, date\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "# from IPython.display import Image\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import normal_\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import re\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "import os\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.utils import logging\n",
    "logger = logging.get_logger(__name__)\n",
    "from filelock import FileLock\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv('/opt/ml/wine/data/wine_df.csv')\n",
    "review_df = pd.read_csv('/opt/ml/wine/data/review_df_total.csv',encoding = 'utf-8-sig').loc[:,['user_url','rating','text','wine_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/opt/ml/wine/code/data/feature_map/item2idx.json','r') as f:\n",
    "    item2idx = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = review_df[review_df['text'].isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['text'] = review_df['text'].apply(lambda x: x + '.' if x[-1] != '.' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_english_and_digits(text):\n",
    "    # Remove any characters that are not English alphabets, digits, periods, or commas at the end of sentences\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9\\s.,]', '', text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['text'] = review_df['text'].apply(keep_english_and_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['wine_id'] = review_df['wine_url'].map(item2idx)\n",
    "review_df = review_df[review_df['wine_id'].isna()==False]\n",
    "review_df['wine_id'] = review_df['wine_id'].astype('int').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_df = wine_df.filter(like='_child')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = {}\n",
    "import ast\n",
    "def str2dict(x):\n",
    "    try: return ast.literal_eval(x)\n",
    "    except: return {}\n",
    "def get_keys(x):\n",
    "    return set(x.keys())\n",
    "\n",
    "for col in note_df.columns:\n",
    "    note_df.loc[:,col] = note_df.loc[:,col].apply(str2dict)\n",
    "    sub_note = set()\n",
    "    for i in tqdm(range(len(note_df))):\n",
    "        subs = get_keys(note_df[col][i])\n",
    "        sub_note = sub_note | subs\n",
    "    notes[col.replace('_child','')] = sub_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_note = review_df.drop(['rating','wine_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 와인 기본 정보 multi label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_basic_info = wine_df.loc[:, ['url','country','region','grape','winetype']]\n",
    "wine_basic_info['wine_id'] = wine_basic_info['url'].map(item2idx)\n",
    "wine_basic_info= wine_basic_info[wine_basic_info['wine_id'].isna()==False]\n",
    "wine_basic_info['wine_id'] = wine_basic_info['wine_id'].astype('int').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_note_in_review(text, notes_data):\n",
    "    text = text.lower()\n",
    "    result = []\n",
    "    for key in notes:\n",
    "        if any(word in text for word in notes[key]):\n",
    "            result.append(1)\n",
    "        else: result.append(0)\n",
    "    return result\n",
    "\n",
    "def marking_data(df, notes_data):\n",
    "    df.reset_index(inplace = True)\n",
    "    data = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        note_onehot = check_note_in_review(df.loc[i,'text'], notes_data)\n",
    "        tmp = {}\n",
    "        tmp['wine_id'] = df.loc[i,'wine_id']\n",
    "        tmp['text'] = df.loc[i,'text']\n",
    "        tmp['note_label'] = note_onehot\n",
    "        data.append(tmp)\n",
    "        \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def parallel_dataframe_2input(func, df, notes_data, num_cpu):\n",
    "\n",
    "    for key in notes_data: notes_data[key] = set(notes_data[key])\n",
    "    chunks = np.array_split(df, num_cpu)\n",
    "\n",
    "    print('Parallelizing with ' +str(num_cpu)+'cores')\n",
    "    with Parallel(n_jobs = num_cpu, backend=\"multiprocessing\") as parallel:\n",
    "        results = parallel(delayed(func)(chunks[i], notes_data) for i in range(num_cpu))\n",
    "\n",
    "    for i,data in enumerate(results):\n",
    "        if i == 0:\n",
    "            output = data\n",
    "        else:\n",
    "            output = pd.concat([output, data], axis=0)\n",
    "    output.reset_index(inplace = True, drop = True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/wine/data/note.json','r') as f: notes_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelizing with 8cores\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-83ff87aef354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_with_notelabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_dataframe_2input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarking_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotes_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-102-b8f808addfb8>\u001b[0m in \u001b[0;36mparallel_dataframe_2input\u001b[0;34m(func, df, notes_data, num_cpu)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Parallelizing with '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'cores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multiprocessing\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotes_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_initialize_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;34m\"\"\"Build a process or thread pool and return the number of workers\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m             n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n\u001b[0m\u001b[1;32m    736\u001b[0m                                              **self._backend_args)\n\u001b[1;32m    737\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_timeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mconfigure\u001b[0;34m(self, n_jobs, parallel, prefer, require, **memmappingpool_args)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;31m# Make sure to free as much memory as possible before forking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMemmappingPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmemmappingpool_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, temp_folder, max_nbytes, mmap_mode, forward_reducers, backward_reducers, verbose, context_id, prewarm, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m                           DeprecationWarning)\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTemporaryResourcesManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_folder_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/_memmapping_reducer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, temp_folder_root, context_id)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m# exposes exposes too many low-level details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mcontext_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_current_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_current_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/_memmapping_reducer.py\u001b[0m in \u001b[0;36mset_current_context\u001b[0;34m(self, context_id)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_current_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_context_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_new_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_new_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/_memmapping_reducer.py\u001b[0m in \u001b[0;36mregister_new_context\u001b[0;34m(self, context_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mnew_folder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_folder_root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             )\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_folder_finalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_temp_folders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_folder_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/_memmapping_reducer.py\u001b[0m in \u001b[0;36mregister_folder_finalizer\u001b[0;34m(self, pool_subfolder, context_id)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# semaphores and pipes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mpool_module_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhichmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelete_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'delete_folder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mresource_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_subfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"folder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/externals/loky/backend/resource_tracker.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, name, rtype)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;34m'''Register a named resource, and increment its refcount.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'REGISTER'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/externals/loky/backend/resource_tracker.py\u001b[0m in \u001b[0;36mensure_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m                         signal.pthread_sigmask(signal.SIG_BLOCK,\n\u001b[1;32m    161\u001b[0m                                                _IGNORED_SIGNALS)\n\u001b[0;32m--> 162\u001b[0;31m                     \u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawnv_passfds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfds_to_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0m_HAVE_SIGMASK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/externals/loky/backend/resource_tracker.py\u001b[0m in \u001b[0;36mspawnv_passfds\u001b[0;34m(path, args, passfds)\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0m_pass\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_mk_inheritable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfork_exec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfork_exec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfork_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrpipe_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/joblib/externals/loky/backend/fork_exec.py\u001b[0m in \u001b[0;36mfork_exec\u001b[0;34m(cmd, keep_fds, env)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mchild_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mclose_fds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_fds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "text_with_notelabel = parallel_dataframe_2input(marking_data, review_df, notes_data, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_notelabel.to_csv('/opt/ml/wine/data/text_with_notelabel.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.comment_text = dataframe.text\n",
    "        self.targets = self.data.label\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comment_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment_text = str(self.comment_text[index])\n",
    "        comment_text = \" \".join(comment_text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            None,\n",
    "            truncation = True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('학습 문장 최대 길이 :',max(len(l) for l in text_with_notelabel['text']))\n",
    "print('학습 문장의 평균 길이 :',sum(map(len, text_with_notelabel['text']))/len(text_with_notelabel['text']))\n",
    "\n",
    "plt.hist([len(s) for s in text_with_notelabel['text']], bins=50)\n",
    "plt.xlabel('length of data')\n",
    "plt.ylabel('number of data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "train_size = 0.8\n",
    "train_dataset = text_with_notelabel.sample(frac=train_size,random_state=200)\n",
    "test_dataset = text_with_notelabel.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"FULL Dataset: {}\".format(text_with_notelabel.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, 156)\n",
    "testing_set = CustomDataset(test_dataset, tokenizer, 156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 512\n",
    "VALID_BATCH_SIZE = 1024\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, num_labels)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2)\n",
    "        return output\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "model = BERTClass(len(text_with_notelabel['label'][0]))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for data in tqdm(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        if _%5000==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    outputs, targets = validation(epoch)\n",
    "    outputs = np.array(outputs) >= 0.5\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info = pd.read_csv('/opt/ml/wine/data/basic_info_total.csv')\n",
    "wine_df = pd.read_csv('/opt/ml/wine/data/wine_df.csv')\n",
    "wine_info = wine_df.loc[:, ['url','winetype']].merge(basic_info, on='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections import defaultdict\n",
    "\n",
    "def str2list(x):\n",
    "    try: return ast.literal_eval(x)\n",
    "    except: return ['None']\n",
    "\n",
    "def get_all_grapes(wine_info):\n",
    "    \n",
    "    unique_grape = defaultdict(int)\n",
    "    for grapes in tqdm(wine_info['grapes']):\n",
    "        for grape in grapes:\n",
    "            grape = re.sub(r'\\d+%_', '', grape).lower()\n",
    "            unique_grape[grape] += 1\n",
    "\n",
    "    return dict(sorted(unique_grape.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grape_encoding(wine_info, grape2idx, threshold):\n",
    "    wine_info.reset_index(drop = True, inplace= True)\n",
    "    grape_onehot = []\n",
    "    for grapes in wine_info['grapes']:\n",
    "        tmp = [0 for _ in range(len(grape2idx))]\n",
    "        for grape in grapes:\n",
    "            if grape in grape2idx:\n",
    "                matches = re.findall(r'(\\d+)%_(\\w+)', grape)\n",
    "\n",
    "                if len(matches) == 1:\n",
    "                    percentage, grape  = matches[0]\n",
    "                    if int(percentage) >= threshold: tmp[grape2idx[grape]] = 1\n",
    "\n",
    "                else: tmp[grape2idx[grape]] = 1\n",
    "        grape_onehot.append(tmp)\n",
    "    wine_info['grape_label'] = grape_onehot\n",
    "    return wine_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_lowcount_feat(df, col, threshold):\n",
    "    feats = {}\n",
    "    idx = 1\n",
    "    for feature, count in zip(df[col].value_counts().index,  df[col].value_counts()):\n",
    "        if count >= threshold:\n",
    "            feats[feature] = idx\n",
    "            idx += 1\n",
    "        else:\n",
    "            feats[feature] = 0\n",
    "    return feats\n",
    "\n",
    "def string2label(df, column, feature2idx):\n",
    "    labels = []\n",
    "    df[column] = df[column].fillna(\"None\")\n",
    "    for feature in tqdm(df[column]):\n",
    "        tmp = [0 for _ in range(max(feature2idx.values())+1)]\n",
    "\n",
    "        if feature in feature2idx:\n",
    "            tmp[feature2idx[feature]] = 1\n",
    "        else: tmp[-1] = 0\n",
    "\n",
    "        labels.append(tmp)\n",
    "        \n",
    "    df[f\"{column}_label\"] = labels\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/opt/ml/wine/code/data/feature_map/item2idx.json','r') as f:\n",
    "    item2idx = json.load(f)\n",
    "wine_info['wine_id'] = wine_info['url'].map(item2idx)\n",
    "wine_info = wine_info[wine_info['wine_id'].isna()==False]\n",
    "wine_info['wine_id'] = wine_info['wine_id'].astype('int').astype('category')\n",
    "wine_info = wine_info.loc[:,['wine_id','country','grapes','winetype']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_labeled_data(\n",
    "        wine_info : pd.DataFrame, \n",
    "        grape_threshold : int = 89, \n",
    "        grape_percentage_threshold : int = 20,\n",
    "        country_threshold : int = 150,\n",
    "        winetype_threshold : int = 0\n",
    "        ):\n",
    "    wine_info.drop_duplicates(inplace = True)\n",
    "    wine_info = wine_info.loc[:,['wine_id','country','grapes','winetype']]\n",
    "    wine_info['country'].fillna('other', inplace = True)\n",
    "    wine_info['winetype'].fillna('other', inplace = True)\n",
    "    wine_info['grapes'] = wine_info['grapes'].apply(str2list)\n",
    "\n",
    "    unique_grape = get_all_grapes(wine_info)\n",
    "    filtered_grape = {k: v for k, v in unique_grape.items() if v >=grape_threshold}\n",
    "    grape2idx =  {k: v for v, k in enumerate(filtered_grape.keys())}\n",
    "\n",
    "    wine_info = grape_encoding(wine_info, grape2idx, grape_percentage_threshold)\n",
    "    sum_zero_filter = lambda x: sum(x) != 0\n",
    "\n",
    "    # Apply the filter and drop rows where the sum of the list is 0\n",
    "    wine_info = wine_info[wine_info['grape_label'].apply(sum_zero_filter)]\n",
    "\n",
    "    country2idx =  cut_lowcount_feat(wine_info, 'country', country_threshold)\n",
    "    winetype2idx = cut_lowcount_feat(wine_info, 'winetype', winetype_threshold)\n",
    "\n",
    "    wine_info = string2label(wine_info, 'winetype', winetype2idx)\n",
    "    wine_info = string2label(wine_info, 'country', country2idx)\n",
    "    wine_info.reset_index(inplace = True, drop = True)\n",
    "    return wine_info, grape2idx, country2idx, winetype2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_info, grape2idx, country2idx, winetype2idx = gen_labeled_data(wine_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_info.to_csv('/opt/ml/wine/data/wine_label_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_price_in_review(text, price_vocab):\n",
    "    price_vocab = set(price_vocab)\n",
    "    text = text.lower()\n",
    "    if any(word in text for word in price_vocab): return [1]\n",
    "    else: return [0]\n",
    "\n",
    "def marking_price_data(df, price_vocab):\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    df['text'] = df['text'].fillna('')\n",
    "    data = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        tmp = {}\n",
    "        tmp['wine_id'] = df.loc[i,'wine_id']\n",
    "        tmp['text'] = df.loc[i,'text']\n",
    "        tmp['label'] = check_price_in_review(df.loc[i,'text'], price_vocab)\n",
    "        data.append(tmp)\n",
    "        \n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7649958/7649958 [04:24<00:00, 28931.42it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('/opt/ml/wine/data/price_vocab.json','r') as f: price_vocab = json.load(f)\n",
    "price_data = marking_price_data(review_df, price_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-9308ff83ffc9>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df['wine_id'] = review_df['wine_id'].astype('int').astype('category')\n",
      "<ipython-input-67-9308ff83ffc9>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df.drop(['index','level_0','user_url','wine_url'], axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "review_df\n",
    "review_df['wine_id'] = review_df['wine_url'].map(item2idx)\n",
    "review_df = review_df[review_df['wine_id'].isna()==False]\n",
    "review_df['wine_id'] = review_df['wine_id'].astype('int').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len_text(x):\n",
    "    return len(x.split())\n",
    "\n",
    "review_df = review_df.sort_values('wine_id')\n",
    "review_df['length'] = review_df['text'].apply(get_len_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = review_df.sort_values(['wine_id', 'length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_short_review(df, threshold):\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    data = []\n",
    "\n",
    "    prv_text = ''\n",
    "    prv_id = df.loc[0, 'wine_id']\n",
    "    \n",
    "    for i in tqdm(range(len(df))):\n",
    "        tmp = {}\n",
    "        \n",
    "        wine_id = df.loc[i, 'wine_id']\n",
    "        length = df.loc[i, 'length']\n",
    "        text = df.loc[i, 'text']\n",
    "        \n",
    "        if length <= threshold: #######short text\n",
    "            if (length + len(prv_text.split()) > threshold):\n",
    "                if wine_id == prv_id:\n",
    "                    text += prv_text\n",
    "                    length += len(prv_text.split())\n",
    "\n",
    "                tmp['wine_id'] = wine_id\n",
    "                tmp['text'] = text\n",
    "                tmp['length'] = length \n",
    "                data.append(tmp)\n",
    "                prv_text = text\n",
    "                prv_id = wine_id\n",
    "                \n",
    "            else: prv_text += text\n",
    "        else: #######long text\n",
    "            tmp['wine_id'] = wine_id\n",
    "            tmp['text'] = text\n",
    "            tmp['length'] = length\n",
    "            data.append(tmp)\n",
    "            prv_text = text\n",
    "            prv_id = wine_id\n",
    "        \n",
    "    result = pd.DataFrame(data)\n",
    "    result = result[result['length'] > 2]\n",
    "    result.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    print(f\"Before : {len(df)}\")\n",
    "    print(f\"After : {len(result)}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7147151 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7147151/7147151 [08:06<00:00, 14698.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : 7147151\n",
      "After : 6721655\n"
     ]
    }
   ],
   "source": [
    "review_df = merge_short_review(review_df, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine_id</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>country</th>\n",
       "      <th>grapes</th>\n",
       "      <th>winetype</th>\n",
       "      <th>grape_label</th>\n",
       "      <th>winetype_label</th>\n",
       "      <th>country_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Amazing</td>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>[tempranillo]</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>Vinaso</td>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>[tempranillo]</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>Vinazo</td>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>[tempranillo]</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>👍</td>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>[tempranillo]</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>Powerful!</td>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>[tempranillo]</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492925</th>\n",
       "      <td>74913</td>\n",
       "      <td>Our 1st bottle of the night and we decided to ...</td>\n",
       "      <td>93</td>\n",
       "      <td>France</td>\n",
       "      <td>[cabernet_sauvignon, cabernet_franc, malbec, m...</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492926</th>\n",
       "      <td>74913</td>\n",
       "      <td>4.2 - very few things in life can beat the nos...</td>\n",
       "      <td>94</td>\n",
       "      <td>France</td>\n",
       "      <td>[cabernet_sauvignon, cabernet_franc, malbec, m...</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492927</th>\n",
       "      <td>74913</td>\n",
       "      <td>A very good old wine of my vintage from an auc...</td>\n",
       "      <td>94</td>\n",
       "      <td>France</td>\n",
       "      <td>[cabernet_sauvignon, cabernet_franc, malbec, m...</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492928</th>\n",
       "      <td>74913</td>\n",
       "      <td>Very nice! One of the best, pleasant, fruity f...</td>\n",
       "      <td>94</td>\n",
       "      <td>France</td>\n",
       "      <td>[cabernet_sauvignon, cabernet_franc, malbec, m...</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492929</th>\n",
       "      <td>74913</td>\n",
       "      <td>For me this wine is about the taste and not ab...</td>\n",
       "      <td>99</td>\n",
       "      <td>France</td>\n",
       "      <td>[cabernet_sauvignon, cabernet_franc, malbec, m...</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1492930 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        wine_id                                               text  length  \\\n",
       "0            40                                            Amazing       1   \n",
       "1            40                                             Vinaso       1   \n",
       "2            40                                             Vinazo       1   \n",
       "3            40                                                  👍       1   \n",
       "4            40                                          Powerful!       1   \n",
       "...         ...                                                ...     ...   \n",
       "1492925   74913  Our 1st bottle of the night and we decided to ...      93   \n",
       "1492926   74913  4.2 - very few things in life can beat the nos...      94   \n",
       "1492927   74913  A very good old wine of my vintage from an auc...      94   \n",
       "1492928   74913  Very nice! One of the best, pleasant, fruity f...      94   \n",
       "1492929   74913  For me this wine is about the taste and not ab...      99   \n",
       "\n",
       "        country                                             grapes  winetype  \\\n",
       "0         Spain                                      [tempranillo]  Red wine   \n",
       "1         Spain                                      [tempranillo]  Red wine   \n",
       "2         Spain                                      [tempranillo]  Red wine   \n",
       "3         Spain                                      [tempranillo]  Red wine   \n",
       "4         Spain                                      [tempranillo]  Red wine   \n",
       "...         ...                                                ...       ...   \n",
       "1492925  France  [cabernet_sauvignon, cabernet_franc, malbec, m...  Red wine   \n",
       "1492926  France  [cabernet_sauvignon, cabernet_franc, malbec, m...  Red wine   \n",
       "1492927  France  [cabernet_sauvignon, cabernet_franc, malbec, m...  Red wine   \n",
       "1492928  France  [cabernet_sauvignon, cabernet_franc, malbec, m...  Red wine   \n",
       "1492929  France  [cabernet_sauvignon, cabernet_franc, malbec, m...  Red wine   \n",
       "\n",
       "                                               grape_label  \\\n",
       "0        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "1        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "2        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "3        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "4        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "...                                                    ...   \n",
       "1492925  [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...   \n",
       "1492926  [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...   \n",
       "1492927  [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...   \n",
       "1492928  [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...   \n",
       "1492929  [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...   \n",
       "\n",
       "                   winetype_label                         country_label  \n",
       "0        [0, 1, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1        [0, 1, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2        [0, 1, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3        [0, 1, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4        [0, 1, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                           ...                                   ...  \n",
       "1492925  [0, 1, 0, 0, 0, 0, 0, 0]  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1492926  [0, 1, 0, 0, 0, 0, 0, 0]  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1492927  [0, 1, 0, 0, 0, 0, 0, 0]  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1492928  [0, 1, 0, 0, 0, 0, 0, 0]  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1492929  [0, 1, 0, 0, 0, 0, 0, 0]  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[1492930 rows x 9 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = pd.merge(review_df, wine_info, on = 'wine_id', how = 'inner')\n",
    "labeled_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
