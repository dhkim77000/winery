{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc9b2bf-3434-4781-a2a4-f056c687dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "from tqdm import tqdm\n",
    "from logging import getLogger\n",
    "import torch\n",
    "\n",
    "from recbole.model.general_recommender.multivae import MultiVAE\n",
    "from recbole.quick_start import run_recbole\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.data import dataset\n",
    "from recbole.data import create_dataset, data_preparation, Interaction\n",
    "from recbole.utils import init_logger, get_trainer, get_model, init_seed, set_color\n",
    "\n",
    "\n",
    "SEED=13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65e8e1-420d-4119-a338-0089bccbdbbd",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f675320-c6b1-45c4-912a-56931dc96231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model_name):\n",
    "\n",
    "    return run_recbole(\n",
    "        model=model_name,\n",
    "        dataset='train_data',\n",
    "        config_file_list=['/opt/ml/backend/Recbole/general.yaml'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c9f0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from recbole.config import Config\n",
    "config_file_list=['/opt/ml/backend/Recbole/general.yaml']\n",
    "model='DCN'\n",
    "dataset='train_data'\n",
    "config = Config(model=model, dataset=dataset, config_file_list=config_file_list)\n",
    "dataset = create_dataset(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cabf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, interaction in enumerate(train_data):    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836efbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(dataset.field2token_id['user_id'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad0ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94be6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_fields = []\n",
    "for field_name in ['user_id','item_id','region']:\n",
    "    token_fields.append(interaction[field_name].unsqueeze(1))\n",
    "if len(token_fields) > 0:\n",
    "    token_fields = torch.cat(\n",
    "        token_fields, dim=1\n",
    "    )  # [batch_size, num_token_field, 2]\n",
    "else:\n",
    "    token_fields = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b331846",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.token_embedding_table\n",
    "model.float_embedding_table\n",
    "model.token_seq_embedding_table\n",
    "model.float_seq_embedding_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f224ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.field2token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59236596-bbd4-41bb-aaba-73ba7902b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc6653-4e9a-465d-a798-18a92f081604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xpip install numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616542d8-b341-4e40-8584-75f1a87e8523",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DCN'\n",
    "print(f\"running {model_name}...\")\n",
    "start = time.time()\n",
    "result = run(model_name)\n",
    "t = time.time() - start\n",
    "print(f\"It took {t/60:.2f} mins\")\n",
    "print(result)\n",
    "# wandb.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b7f545-2d89-47c2-b0b5-6c604cdbdbcc",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a47a3a9-eb11-432c-9f05-13795aa1554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='/opt/ml/backend/Recbole/saved/DCN-Jul-19-2023_10-30-59.pth'\n",
    "# rank K 설정\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df6d29e-2527-4c5f-abb6-17de744f08ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataset start!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate dataset start!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m train_data, valid_data, test_data \u001b[38;5;241m=\u001b[39m data_preparation(config, dataset)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate dataset done!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/data/utils.py:70\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     67\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(set_color(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad filtered dataset from\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpink\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[0;32m---> 70\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     72\u001b[0m     dataset\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py:108\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;241m=\u001b[39m getLogger()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_scratch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py:118\u001b[0m, in \u001b[0;36mDataset._from_scratch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_preset()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_field_from_config()\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_alias()\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_processing()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py:268\u001b[0m, in \u001b[0;36mDataset._load_data\u001b[0;34m(self, token, dataset_path)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(dataset_path):\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download()\n\u001b[0;32m--> 268\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_inter_feat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_user_or_item_feat(\n\u001b[1;32m    270\u001b[0m     token, dataset_path, FeatureSource\u001b[38;5;241m.\u001b[39mUSER, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muid_field\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m )\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_user_or_item_feat(\n\u001b[1;32m    273\u001b[0m     token, dataset_path, FeatureSource\u001b[38;5;241m.\u001b[39mITEM, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miid_field\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py:295\u001b[0m, in \u001b[0;36mDataset._load_inter_feat\u001b[0;34m(self, token, dataset_path)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(inter_feat_path):\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minter_feat_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 295\u001b[0m inter_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_feat\u001b[49m\u001b[43m(\u001b[49m\u001b[43minter_feat_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFeatureSource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTERACTION\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInteraction feature loaded successfully from [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minter_feat_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m )\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minter_feat \u001b[38;5;241m=\u001b[39m inter_feat\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/recbole/data/dataset/dataset.py:486\u001b[0m, in \u001b[0;36mDataset._load_feat\u001b[0;34m(self, filepath, source)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo columns has been loaded from [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_separator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m columns\n\u001b[1;32m    496\u001b[0m seq_separator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_separator\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py:610\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    605\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    606\u001b[0m     dialect, delimiter, delim_whitespace, engine, sep, defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    607\u001b[0m )\n\u001b[1;32m    608\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py:468\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py:1057\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1056\u001b[0m     nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m-> 1057\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m col_dict:\n\u001b[1;32m   1061\u001b[0m             \u001b[38;5;66;03m# Any column is actually fine:\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py:2440\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2439\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2440\u001b[0m         content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2441\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   2442\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py:3242\u001b[0m, in \u001b[0;36mPythonParser._get_lines\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   3239\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3241\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 3242\u001b[0m     new_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_iter_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3243\u001b[0m     rows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers.py:2943\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m   2940\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2941\u001b[0m     \u001b[38;5;66;03m# assert for mypy, data is Iterator[str] or None, would error in next\u001b[39;00m\n\u001b[1;32m   2942\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2943\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2944\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m csv\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2945\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_bad_lines \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_bad_lines:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "# config, model, dataset 불러오기\n",
    "checkpoint = torch.load(model_path)\n",
    "config = checkpoint['config']\n",
    "config['dataset'] = 'train_data'\n",
    "\n",
    "print(\"create dataset start!\")\n",
    "dataset = create_dataset(config)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "print(\"create dataset done!\")\n",
    "\n",
    "model = get_model(config['model'])(config, test_data.dataset).to(config['device'])\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.load_other_parameter(checkpoint.get('other_parameter'))\n",
    "\n",
    "# device 설정\n",
    "device = config.final_config_dict['device']\n",
    "\n",
    "# user, item id -> token 변환 array\n",
    "user_id = config['USER_ID_FIELD']\n",
    "item_id = config['ITEM_ID_FIELD']\n",
    "user_id2token = dataset.field2id_token[user_id]\n",
    "item_id2token = dataset.field2id_token[item_id]\n",
    "\n",
    "# user id list\n",
    "user_count = len(user_id2token)\n",
    "remainder = user_count % 128\n",
    "padding_size = 128 - remainder if remainder != 0 else 0\n",
    "all_user_list = torch.arange(0, user_count + padding_size).reshape(-1, 128)\n",
    "\n",
    "# # user id list\n",
    "# item_count = len(item_id2token)\n",
    "# remainder = item_count % 128\n",
    "# padding_size = 128 - remainder if remainder != 0 else 0\n",
    "# all_item_list = torch.arange(0, item_count + padding_size).reshape(-1, 128)\n",
    "\n",
    "# user, item 길이\n",
    "user_len = len(user_id2token)\n",
    "item_len = len(item_id2token)\n",
    "\n",
    "# user-item sparse matrix\n",
    "matrix = dataset.inter_matrix(form='csr')\n",
    "\n",
    "# user id, predict item id 저장 변수\n",
    "pred_list = None\n",
    "user_list = None\n",
    "\n",
    "# model 평가모드 전환\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# progress bar 설정\n",
    "tbar = tqdm(all_user_list, desc=set_color(f\"Inference\", 'pink'))\n",
    "for data in tbar:\n",
    "    batch_pred_list = full_sort_topk(data, model, test_data, K, device=device)[1]\n",
    "    batch_pred_list = batch_pred_list.clone().detach().cpu().numpy()\n",
    "    if pred_list is None:\n",
    "        pred_list = batch_pred_list\n",
    "        user_list = data.numpy()\n",
    "    else:\n",
    "        pred_list = np.append(pred_list, batch_pred_list, axis=0)\n",
    "        user_list = np.append(\n",
    "            user_list, data.numpy(), axis=0\n",
    "        )\n",
    "tbar.close()\n",
    "\n",
    "\n",
    "result = []\n",
    "for user, pred in zip(user_list, pred_list):\n",
    "    for item in pred:\n",
    "        result.append((int(user_id2token[user]), int(item_id2token[item])))\n",
    "\n",
    "#데이터 저장\n",
    "sub = pd.DataFrame(result, columns=[\"user\", \"item\"])\n",
    "\n",
    "# # 데이터 저장\n",
    "# sub = pd.DataFrame(result, columns=[\"user\", \"item\"])\n",
    "# sub.to_csv(\n",
    "#     \"submission.csv\", index=False\n",
    "\n",
    "print('inference done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc7f99-1339-45a3-a16e-2e763bc0e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config, model, dataset 불러오기\n",
    "checkpoint = torch.load(model_path)\n",
    "config = checkpoint['config']\n",
    "config['dataset'] = 'train_data'\n",
    "\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "print(\"create dataset start!\")\n",
    "dataset = create_dataset(config)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "print(\"create dataset done!\")\n",
    "model = get_model(config['model'])(config, test_data.dataset).to(config['device'])\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.load_other_parameter(checkpoint.get('other_parameter'))\n",
    "\n",
    "# device 설정\n",
    "device = config.final_config_dict['device']\n",
    "\n",
    "# user, item id -> token 변환 array\n",
    "user_id = config['USER_ID_FIELD']\n",
    "item_id = config['ITEM_ID_FIELD']\n",
    "user_id2token = dataset.field2id_token[user_id]\n",
    "item_id2token = dataset.field2id_token[item_id]\n",
    "\n",
    "# user id list\n",
    "\n",
    "user_count = len(user_id2token)\n",
    "remainder = user_count % 128\n",
    "padding_size = 128 - remainder if remainder != 0 else 0\n",
    "all_user_list = torch.arange(1, user_count + padding_size+1).reshape(-1, 128)\n",
    "user_id2token = user_id2token[1:]\n",
    "# user, item 길이\n",
    "user_len = len(user_id2token)\n",
    "item_len = len(item_id2token)\n",
    "\n",
    "# user-item sparse matrix\n",
    "# matrix = dataset.inter_matrix(form='csr')\n",
    "\n",
    "# user id, predict item id 저장 변수\n",
    "pred_list = None\n",
    "user_list = []\n",
    "\n",
    "# model 평가모드 전환\n",
    "model.eval()\n",
    "\n",
    "# progress bar 설정\n",
    "tbar = tqdm(range(user_len), desc=set_color(f\"Inference\", 'pink'))\n",
    "for user in tbar:\n",
    "    # 모델에 입력할 사용자 ID를 토큰으로 변환하여 추론\n",
    "    user_id_token = user_id2token[user]\n",
    "    if user_id_token != '[PAD]':\n",
    "        user_id_token = int(user_id_token)\n",
    "        user_input = torch.tensor([user_id_token], dtype=torch.long).to(device)\n",
    "\n",
    "    # 모델로부터 아이템 예측 점수를 얻습니다.\n",
    "    # 이 때, 아이템 예측 점수를 오름차순으로 정렬하고 상위 K개를 선택합니다.\n",
    "    pdb.set_trace()\n",
    "    with torch.no_grad():\n",
    "        item_scores = model(user_input)\n",
    "        _, topk_items = torch.topk(item_scores, k=K)\n",
    "\n",
    "    # 예측 결과를 리스트에 저장합니다.\n",
    "    for item in topk_items[0]:\n",
    "        result.append((user, int(item_id2token[item])))\n",
    "\n",
    "tbar.close()\n",
    "\n",
    "\n",
    "result = []\n",
    "for user, pred in zip(user_list, pred_list):\n",
    "    for item in pred:\n",
    "        result.append((int(user_id2token[user]), int(item_id2token[item])))\n",
    "\n",
    "#데이터 저장\n",
    "sub = pd.DataFrame(result, columns=[\"user\", \"item\"])\n",
    "print(len(sub))\n",
    "print('inference done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b85240e-5bc4-4bd7-b23a-16f0240173f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='/opt/ml/backend/Recbole/saved/FM-Jul-21-2023_14-59-29.pth'\n",
    "# rank K 설정\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acfb5959-642e-4a07-957b-4a7233b052e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create dataset start!\n",
      "create dataset done!\n"
     ]
    }
   ],
   "source": [
    "# config, model, dataset 불러오기\n",
    "checkpoint = torch.load(model_path)\n",
    "config = checkpoint['config']\n",
    "config['dataset'] = 'train_data'\n",
    "\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "print(\"create dataset start!\")\n",
    "dataset = create_dataset(config)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "print(\"create dataset done!\")\n",
    "model = get_model(config['model'])(config, test_data.dataset).to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c194eb3a-6e70-4f48-9fd7-aafcd432c328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of train_data: <class 'recbole.data.dataloader.general_dataloader.TrainDataLoader'>\n",
      "Type of valid_data: <class 'recbole.data.dataloader.general_dataloader.NegSampleEvalDataLoader'>\n",
      "Type of test_data: <class 'recbole.data.dataloader.general_dataloader.NegSampleEvalDataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of train_data:\", type(train_data))\n",
    "print(\"Type of valid_data:\", type(valid_data))\n",
    "print(\"Type of test_data:\", type(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "551e205f-9fab-49a5-ac2e-b69e7e7aeb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole.utils.case_study import full_sort_topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a4f7b38-cc01-4f39-98e8-4342ad897e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = config['USER_ID_FIELD']\n",
    "item_id = config['ITEM_ID_FIELD']\n",
    "user_id2token = dataset.field2id_token[user_id]\n",
    "item_id2token = dataset.field2id_token[item_id]\n",
    "\n",
    "# user id list\n",
    "batch_size = 64\n",
    "user_count = len(user_id2token)\n",
    "remainder = user_count % batch_size\n",
    "padding_size = batch_size - remainder if remainder != 0 else 0\n",
    "all_user_list = torch.arange(0, user_count + padding_size).reshape(-1, batch_size)\n",
    "user_id2token = user_id2token[1:]\n",
    "# user, item 길이\n",
    "user_len = len(user_id2token)\n",
    "item_len = len(item_id2token)\n",
    "\n",
    "# user-item sparse matrix\n",
    "# matrix = dataset.inter_matrix(form='csr')\n",
    "\n",
    "# user id, predict item id 저장 변수\n",
    "pred_list = None\n",
    "user_list = []\n",
    "\n",
    "# model 평가모드 전환\n",
    "model.eval()\n",
    "matrix = dataset.inter_matrix(form='csr')\n",
    "# device 설정\n",
    "device = config.final_config_dict['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6683957a-7e69-4aef-a517-74b1fbcb881a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[      0,       1,       2,  ...,      61,      62,      63],\n",
       "        [     64,      65,      66,  ...,     125,     126,     127],\n",
       "        [    128,     129,     130,  ...,     189,     190,     191],\n",
       "        ...,\n",
       "        [1154624, 1154625, 1154626,  ..., 1154685, 1154686, 1154687],\n",
       "        [1154688, 1154689, 1154690,  ..., 1154749, 1154750, 1154751],\n",
       "        [1154752, 1154753, 1154754,  ..., 1154813, 1154814, 1154815]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e0f34-a9aa-4830-b5a2-fd4a6c789acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInference\u001b[0m:  45%|████▍     | 8075/18044 [21:30<29:42,  5.59it/s]"
     ]
    }
   ],
   "source": [
    "tbar = tqdm(all_user_list, desc=set_color(f\"Inference\", 'pink'))\n",
    "import gc\n",
    "with torch.no_grad():\n",
    "    for data in tbar:\n",
    "        if data.max() > len(user_id2token):\n",
    "            data = [item for item in data if item < 1154808]\n",
    "            data = torch.tensor(data)\n",
    "        # interaction 생성\n",
    "        interaction = Interaction({})\n",
    "        interaction[user_id] = data.to(device)\n",
    "        interaction = interaction.repeat_interleave(dataset.item_num)\n",
    "        interaction.update(\n",
    "            test_data.dataset.get_item_feature().to(device).repeat(len(data))\n",
    "        )\n",
    "\n",
    "        # user item별 score 예측\n",
    "        score = model.predict(interaction)\n",
    "        score = score.view(-1, item_len)\n",
    "        rating_pred = score.cpu().data.numpy().copy()\n",
    "\n",
    "        user_index = data.numpy()\n",
    "\n",
    "        idx = matrix[user_index].toarray() > 0\n",
    "\n",
    "        rating_pred[idx] = -np.inf\n",
    "        rating_pred[:, 0] = -np.inf\n",
    "        ind = np.argpartition(rating_pred, -K)[:, -K:]\n",
    "\n",
    "        arr_ind = rating_pred[np.arange(len(rating_pred))[:, None], ind]\n",
    "\n",
    "        arr_ind_argsort = np.argsort(arr_ind)[np.arange(len(rating_pred)), ::-1]\n",
    "\n",
    "        batch_pred_list = ind[\n",
    "            np.arange(len(rating_pred))[:, None], arr_ind_argsort\n",
    "        ]\n",
    "\n",
    "        if pred_list is None:\n",
    "            pred_list = batch_pred_list\n",
    "            user_list = user_index\n",
    "        else:\n",
    "            pred_list = np.append(pred_list, batch_pred_list, axis=0)\n",
    "            user_list = np.append(\n",
    "                user_list, user_index, axis=0\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5e9a603-1113-4bb2-b5ee-85546c860744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# user_list를 key로, pred_list를 value로 갖는 dictionary 생성\n",
    "data_dict = {str(user_id): pred_list[i].tolist() for i, user_id in enumerate(user_list)}\n",
    "\n",
    "# dictionary를 JSON 형태로 변환\n",
    "json_data = json.dumps(data_dict)\n",
    "\n",
    "# JSON 문자열을 다시 딕셔너리로 디코딩\n",
    "decoded_data = json.loads(json_data)\n",
    "\n",
    "# JSON 데이터를 파일에 저장\n",
    "file_path = \"inference.json\"  # 원하는 파일 경로와 이름 설정\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(json_data)\n",
    "# 디코딩된 데이터 사용\n",
    "# print(decoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df6bd9da-3d83-4ecd-a941-40646b64c569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1154808"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b896316-6e8b-4e2d-8c5b-3e8fee793ff3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoded_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdecoded_data\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoded_data' is not defined"
     ]
    }
   ],
   "source": [
    "decoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328af15-601f-477c-be0b-c9a550ba452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for user, pred in zip(user_list, pred_list):\n",
    "    for item in pred:\n",
    "        result.append((int(user_id2token[user]), int(item_id2token[item])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f7019-5b32-4b2c-ac5f-04283266a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59905008-7f7f-43da-b27b-438d5ad96858",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id2token.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7f1548-b6bf-4c4b-bd86-bed7cc49a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(user_id2token , lambda key = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857428b-39db-44b9-a8e9-f96161a9ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.argsort(user_id2token)\n",
    "sorted_user_id2token = {k: v for k, v in enumerate(sorted_indices)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3b3e6-6e57-4755-a919-a8b9a6c338de",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f29c5-c088-4756-9931-c9c7de7082d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2a974-6661-4b01-b50d-ebd99a3c8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce774bbd-9723-416e-85f3-5befd4b2390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb94b38a-d4f6-42e0-8533-f2430392073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in tbar:\n",
    "    print(data)\n",
    "    batch_pred_list = full_sort_topk(data, model, train_data, K, device=device)[1]\n",
    "    batch_pred_list = batch_pred_list.clone().detach().cpu().numpy()\n",
    "    if pred_list is None:\n",
    "        pred_list = batch_pred_list\n",
    "        user_list = data.numpy()\n",
    "    else:\n",
    "        pred_list = np.append(pred_list, batch_pred_list, axis=0)\n",
    "        user_list = np.append(\n",
    "            user_list, data.numpy(), axis=0\n",
    "        )\n",
    "\n",
    "print(user_list, pred_list)\n",
    "result = []\n",
    "for user, pred in zip(user_list, pred_list):\n",
    "    for item in pred:\n",
    "        result.append((int(user_id2token[user]), int(item_id2token[item])))\n",
    "\n",
    "#데이터 저장\n",
    "sub = pd.DataFrame(result, columns=[\"user\", \"item\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7665c3-bb8f-4a9f-8432-1fe0cfd30cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbar = tqdm(all_user_list, desc=set_color(f\"Inference\", 'pink'))\n",
    "user_id = config['USER_ID_FIELD']\n",
    "item_id = config['ITEM_ID_FIELD']\n",
    "user_id2token = dataset.field2id_token[user_id]\n",
    "item_id2token = dataset.field2id_token[item_id]\n",
    "# device 설정\n",
    "print(user_id)\n",
    "device = config.final_config_dict['device']\n",
    "for data in test_data:\n",
    "    interaction = data[0].to(device)\n",
    "    print(interaction)\n",
    "    score = model.full_sort_predict(interaction)\n",
    "    break\n",
    "    \n",
    "    interaction = interaction.to(device)\n",
    "\n",
    "    # user item별 score 예측\n",
    "    score = model.full_sort_predict(interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a71bf85-c453-4bd5-adf4-75e936e20a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.user = sub.user.map(uidx2user)\n",
    "sub.item = sub.item.map(iidx2item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c507e6f-1ee7-418a-b9df-d8b2e3371724",
   "metadata": {},
   "source": [
    "# 추천 결과 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8223f0a2-2e72-49d2-8623-8ce7d218736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE OUTPUT\n",
    "output_dir = '/opt/ml/input/Recbole/output/'\n",
    "write_path = os.path.join(output_dir, \"MultiVAE.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"user,item\\n\")\n",
    "    for id, p in sub.values:\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56aceb-d797-4512-b7a4-2521774fb0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub / 0.06/ 0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dea9f0-1ec0-4c72-ae41-d758fe307acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
